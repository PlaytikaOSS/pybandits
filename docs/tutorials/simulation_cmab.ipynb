{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation cMAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a simulation framework for the contextual multi-armed bandit (cMAB). It allows to study the behaviour of the bandit algoritm, to evaluate results and to run experiments on simulated data under different context, reward and action settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from pybandits.core.cmab import Cmab\n",
    "from pybandits.utils.simulation_cmab import SimulationCmab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the simulation parameters: (i) the number of samples per batch to consider at each iteration of the simulation, (ii) the number of samples groups (we assume to have groups of samples whose features come from the same distribution), (iii) the numbe of updates in the simulation, (iv) the list of possible actions, (v) the number of features in the context matrix.\n",
    "\n",
    "Data are processed in batches of size n>=1. Per each batch of simulated samples, the cMAB selects one action and collects the corresponding simulated reward for each sample. Then, prior parameters are updated based on returned rewards from recommended actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters\n",
    "batch_size = 100\n",
    "n_groups = 3\n",
    "n_updates = 5\n",
    "n_jobs = 1\n",
    "actions_ids = [\"action A\", \"action B\", \"action C\"]\n",
    "n_features = 5\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we init the context matrix $X$ and the groups of samples. Samples that belong to the same group have features that come from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init context matrix and groups\n",
    "X, group = make_classification(\n",
    "    n_samples=batch_size * n_updates, n_features=n_features, n_informative=n_features, n_redundant=0, n_classes=n_groups\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the probabilities of positive rewards per each action/group, i.e. the ground truth ('Action A': 0.8 for group '0' means that if the bandits selects 'Action A' for samples that belong to group '0', then the environment will return a positive reward with 80% probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init probability of rewards from the environment\n",
    "prob_rewards = pd.DataFrame(\n",
    "    [[0.05, 0.80, 0.05], [0.80, 0.05, 0.05], [0.80, 0.05, 0.80]], columns=actions_ids, index=range(n_groups)\n",
    ")\n",
    "print(\"Probability of positive reward for each group/action:\")\n",
    "prob_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We initialize the Cmab as shown in the previous notebook and the SimulationCmab with the parameters set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init contextual Multi-Armed Bandit model\n",
    "cmab = Cmab(n_features=n_features, actions_ids=actions_ids, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init simulation\n",
    "sim = SimulationCmab(\n",
    "    cmab=cmab, X=X, group=group, batch_size=batch_size, n_updates=n_updates, prob_rewards=prob_rewards, verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start simulation process by executing run() which performs the following steps:\n",
    "```\n",
    "For i=0 to n_updates:\n",
    "    Extract batch[i] of samples from X\n",
    "    Model recommends the best actions as the action with the highest reward probability to each simulated sample in batch[i] and collect corresponding simulated rewards\n",
    "    Model priors are updated using information from recommended actions and returned rewards\n",
    "```\n",
    "Finally, we can visualize the results of the simulation. As defined in the ground truth: 'Action B' was the action recommended the most for samples that belong to group '0', 'Action A' to group '1' and both 'Action A' and 'Action C' to group '2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "mab",
   "language": "python",
   "name": "mab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
