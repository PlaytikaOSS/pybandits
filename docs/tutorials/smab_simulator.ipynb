{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation cMAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a simulation framework for the contextual multi-armed bandit (cMAB). It allows to study the behaviour of the bandit algoritm, to evaluate results and to run experiments on simulated data under different context, reward and action settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from pybandits.core.cmab import Cmab\n",
    "from pybandits.utils.simulation_cmab import SimulationCmab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the simulation parameters: (i) the number of samples per batch to consider at each iteration of the simulation, (ii) the number of samples groups (we assume to have groups of samples whose features come from the same distribution), (iii) the numbe of updates in the simulation, (iv) the list of possible actions, (v) the number of features in the context matrix.\n",
    "\n",
    "Data are processed in batches of size n>=1. Per each batch of simulated samples, the cMAB selects one action and collects the corresponding simulated reward for each sample. Then, prior parameters are updated based on returned rewards from recommended actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters\n",
    "batch_size = 100\n",
    "n_groups = 3\n",
    "n_updates = 5\n",
    "n_jobs = 1\n",
    "actions_ids = [\"action A\", \"action B\", \"action C\"]\n",
    "n_features = 5\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we init the context matrix $X$ and the groups of samples. Samples that belong to the same group have features that come from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init context matrix and groups\n",
    "X, group = make_classification(\n",
    "    n_samples=batch_size * n_updates, n_features=n_features, n_informative=n_features, n_redundant=0, n_classes=n_groups\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the probabilities of positive rewards per each action/group, i.e. the ground truth ('Action A': 0.8 for group '0' means that if the bandits selects 'Action A' for samples that belong to group '0', then the environment will return a positive reward with 80% probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of positive reward for each group/action:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action A</th>\n",
       "      <th>action B</th>\n",
       "      <th>action C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action A  action B  action C\n",
       "0      0.05      0.80      0.05\n",
       "1      0.80      0.05      0.05\n",
       "2      0.80      0.05      0.80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init probability of rewards from the environment\n",
    "prob_rewards = pd.DataFrame(\n",
    "    [[0.05, 0.80, 0.05], [0.80, 0.05, 0.05], [0.80, 0.05, 0.80]], columns=actions_ids, index=range(n_groups)\n",
    ")\n",
    "print(\"Probability of positive reward for each group/action:\")\n",
    "prob_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We initialize the Cmab as shown in the previous notebook and the SimulationCmab with the parameters set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init contextual Multi-Armed Bandit model\n",
    "cmab = Cmab(n_features=n_features, actions_ids=actions_ids, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup simulation  completed.\n",
      "Simulated input probability rewards:\n",
      "        action A  action B  action C\n",
      "group                              \n",
      "0      0.041176  0.835294  0.052941\n",
      "1      0.819277  0.036145  0.054217\n",
      "2      0.786585  0.042683  0.817073 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init simulation\n",
    "sim = SimulationCmab(\n",
    "    cmab=cmab, X=X, group=group, batch_size=batch_size, n_updates=n_updates, prob_rewards=prob_rewards, verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start simulation process by executing run() which performs the following steps:\n",
    "```\n",
    "For i=0 to n_updates:\n",
    "    Extract batch[i] of samples from X\n",
    "    Model recommends the best actions as the action with the highest reward probability to each simulated sample in batch[i] and collect corresponding simulated rewards\n",
    "    Model priors are updated using information from recommended actions and returned rewards\n",
    "```\n",
    "Finally, we can visualize the results of the simulation. As defined in the ground truth: 'Action B' was the action recommended the most for samples that belong to group '0', 'Action A' to group '1' and both 'Action A' and 'Action C' to group '2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1\n",
      "Start predict batch 1 ...\n",
      "Start update batch 1 ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 11 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 10 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 4 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #2\n",
      "Start predict batch 2 ...\n",
      "Start update batch 2 ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 9 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 5 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 3 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #3\n",
      "Start predict batch 3 ...\n",
      "Start update batch 3 ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 9 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 4 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 3 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #4\n",
      "Start predict batch 4 ...\n",
      "Start update batch 4 ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 4 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 3 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 3 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #5\n",
      "Start predict batch 5 ...\n",
      "Start update batch 5 ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 3 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 4 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [beta4, beta3, beta2, beta1, beta0, alpha]\n",
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 3 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation results (first 10 observations):\n",
      "      action  reward  group  selected_prob_reward  max_prob_reward  regret  \\\n",
      "0  action C     0.0      1                  0.05              0.8    0.75   \n",
      "1  action C     1.0      2                  0.80              0.8    0.00   \n",
      "2  action B     1.0      0                  0.80              0.8    0.00   \n",
      "3  action C     0.0      1                  0.05              0.8    0.75   \n",
      "4  action C     0.0      1                  0.05              0.8    0.75   \n",
      "5  action B     1.0      0                  0.80              0.8    0.00   \n",
      "6  action A     0.0      0                  0.05              0.8    0.75   \n",
      "7  action C     0.0      2                  0.80              0.8    0.00   \n",
      "8  action C     0.0      1                  0.05              0.8    0.75   \n",
      "9  action C     1.0      2                  0.80              0.8    0.00   \n",
      "\n",
      "   cum_regret  \n",
      "0        0.75  \n",
      "1        0.75  \n",
      "2        0.75  \n",
      "3        1.50  \n",
      "4        2.25  \n",
      "5        2.25  \n",
      "6        3.00  \n",
      "7        3.00  \n",
      "8        3.75  \n",
      "9        3.75   \n",
      "\n",
      "Count of actions selected by the bandit: \n",
      " {'group 0': {'action B': 85, 'action A': 53, 'action C': 32}, 'group 1': {'action A': 109, 'action C': 31, 'action B': 26}, 'group 2': {'action A': 70, 'action C': 59, 'action B': 35}} \n",
      "\n",
      "Observed proportion of positive rewards for each action:\n",
      " {'group 0': {'action B': 0.788235294117647, 'action A': 0.03773584905660377, 'action C': 0.03125}, 'group 1': {'action A': 0.7981651376146789, 'action B': 0.07692307692307693, 'action C': 0.03225806451612903}, 'group 2': {'action A': 0.7142857142857143, 'action C': 0.8305084745762712, 'action B': 0.02857142857142857}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim.run()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "mab",
   "language": "python",
   "name": "mab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
