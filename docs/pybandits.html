<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Multi-Armed Bandit Library &mdash; PyBandits 1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->

        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="PyBandits Documentation" href="index.html" />
</head>

<body class="wy-body-for-nav">
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> PyBandits
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Multi-Armed Bandit Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="help.html">Help</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyBandits</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Multi-Armed Bandit Library</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/pybandits.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">


<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="multi-armed-bandit-library">
<h1>Multi-Armed Bandit Library<a class="headerlink" href="#multi-armed-bandit-library" title="Permalink to this headline"></a></h1>
<a class="reference external image-reference" href="https://img.shields.io/badge/build-passing-brightgreen"><img alt="Build Status" src="https://img.shields.io/badge/build-passing-brightgreen" /></a>
<a class="reference external image-reference" href="https://img.shields.io/badge/docs-passing-brightgreen"><img alt="Documentation Status" src="https://img.shields.io/badge/docs-passing-brightgreen" /></a>
<a class="reference external image-reference" href="https://img.shields.io/badge/coverage-82%25-green"><img alt="Code coverage" src="https://img.shields.io/badge/coverage-82%25-green" /></a>
<a class="reference external image-reference" href="https://img.shields.io/badge/version-0.0.2-blue"><img alt="Version" src="https://img.shields.io/badge/version-0.0.2-blue" /></a>
<a class="reference external image-reference" href="https://img.shields.io/badge/license-MIT-blue"><img alt="Version" src="https://img.shields.io/badge/license-MIT-blue" /></a>
<p>PyBandits is a Python library for Multi-Armed Bandit (MAB) developed by the Playtika AI lab. We developed this tool in order to provide personalised recommendation. It provides an implementation of stochastic Multi-Armed Bandit (sMAB) and contextual Multi-Armed Bandit (cMAB) based on Thompson sampling.</p>
<p>In a bandit problem, a learner recommends an action to a user and observes a reward from the user for the chosen action. Information is then used to improve learner prediction for the next user.</p>
<p>For the stochastic multi-armed bandit (sMAB),
we implemented a Bernoulli multi-armed bandit based on Thompson sampling algorithm
(<a class="reference external" href="http://proceedings.mlr.press/v23/agrawal12/agrawal12.pdf">Agrawal and Goyal, 2012</a>).
If user information is available (‘context’), a generalisation of Thompson Sampling for cMAB (<a class="reference external" href="https://arxiv.org/pdf/1209.3352.pdf">Agrawal and Goyal, 2014</a>) has been implemented using PyMC3.</p>
<p><a class="reference external" href="https://docs.pymc.io/">PyMC3</a> is an open source
probabilistic programming framework that allows for automatic Bayesian inference on user-defined probabilistic
models. A major advantage of this package is its flexibility and extensibility that allows
the implementation of a large variety of models for prior and likelihood distributions. Currently the cMAB implements a robust logistic regression for binary rewards (Bernoulli bandit) with Student-t priors. A robust regression
is less sensitive to outliers since Student’s T for prior distributions have wider tails than Normal distributions.
Despite binary reward is very common, the package will be updated in order to extend to other reward definitions.
However, as an open-source package, modification can easily be applied to our functions in order to modify priors
and/or likelihood distributions as described in <a class="reference external" href="https://docs.pymc.io/">PyMC3</a> documentation for the cMAB.
In order to observed bandit behaviours based on different assumptions (sample size, reward probabilities,
number of actions, context dimension …) or validate modifications, a simulation process is available. One can
simulate data using different parameters setting, apply sMAB or cMAB and observe recommendation efficiency.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="PyBandits Documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="installation.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MIT License.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

</body>
</html>
